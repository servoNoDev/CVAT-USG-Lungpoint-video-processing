{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import string\n",
    "import random as rand\n",
    "import ast\n",
    "from typing import Any, List, Tuple, Union\n",
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "CVAT_FOLDER_PATH = \"/home/mh731nk/_data/experiments_tmp/data/revision_8/cvat_project_raw_unzip\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read video DataFrame \n",
    "Data was prepared in the previous part of the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(344, 12)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset path\n",
    "df_videos = pd.read_pickle(\"/home/mh731nk/_data/experiments_tmp/data/revision_8/video.pkl\", 'zip')\n",
    "df_videos.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select videos for experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LP -> 17\n",
      "A -> 9\n",
      "P -> 26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtere_videos = df_videos.loc[df_videos[\"folder_class\"].isin([\n",
    "    'USG - Lung point',\n",
    "    'USG - Lung sliding absent (aj ine znaky - radiol. klin.)',\n",
    "    'USG - Lung sliding present (aj ine znaky - radiol. klin.)'\n",
    "    ])]\n",
    "\n",
    "print(f'LP -> {df_filtere_videos.loc[df_filtere_videos[\"folder_class\"] == \"USG - Lung point\"].shape[0]}')\n",
    "print(f'A -> {df_filtere_videos.loc[df_filtere_videos[\"folder_class\"] == \"USG - Lung sliding absent (aj ine znaky - radiol. klin.)\"].shape[0]}')\n",
    "print(f'P -> {df_filtere_videos.loc[df_filtere_videos[\"folder_class\"] == \"USG - Lung sliding present (aj ine znaky - radiol. klin.)\"].shape[0]}')\n",
    "17 + 9 + 26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read anotations for videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_generator(self, size: int = 8, chars: str = string.ascii_uppercase + string.digits) -> str:\n",
    "    \"\"\"\n",
    "    Generate a random string identifier.\n",
    "\n",
    "    This method generates a random string of the specified size using a secure random\n",
    "    generator. By default, the generated string consists of uppercase letters and digits.\n",
    "\n",
    "    Args:\n",
    "        size (int): The length of the generated string. Defaults to 8.\n",
    "        chars (str): A string containing the set of characters to choose from.\n",
    "                     Defaults to uppercase letters and digits (A-Z, 0-9).\n",
    "\n",
    "    Returns:\n",
    "        str: A randomly generated string identifier.\n",
    "    \"\"\"\n",
    "    return ''.join(random.SystemRandom().choice(chars) for _ in range(size))\n",
    "\n",
    "\n",
    "def parse_polygon_points(pts: Union[str, List[Any]]) -> List[Tuple[Union[int, float], Union[int, float]]]:\n",
    "    \"\"\"\n",
    "    Parse and normalize polygon points into a list of (x, y) coordinate pairs.\n",
    "    \n",
    "    The input can be provided in different formats:\n",
    "    - A string representation of a list (e.g., \"[556.9, 200.3, 555.3, 214.0, ...]\"), \n",
    "      which will be evaluated into a Python list.\n",
    "    - A flat list of numbers representing coordinates (e.g., [x0, y0, x1, y1, ...]).\n",
    "    - A list already containing (x, y) pairs.\n",
    "    \n",
    "    The function ensures that the returned value is always a list of tuples,\n",
    "    where each tuple represents a point as (x, y).\n",
    "    \n",
    "    Args:\n",
    "        pts (Union[str, List[Any]]): The polygon points in one of the accepted formats.\n",
    "    \n",
    "    Returns:\n",
    "        List[Tuple[Union[int, float], Union[int, float]]]: A list of (x, y) coordinate pairs.\n",
    "    \"\"\"\n",
    "    # If pts is a string, safely evaluate it to convert the string into a Python list.\n",
    "    if isinstance(pts, str):\n",
    "        pts = ast.literal_eval(pts)\n",
    "    \n",
    "    # If the list is a flat list of coordinates (e.g., [x0, y0, x1, y1, ...]),\n",
    "    # then group the numbers into (x, y) pairs.\n",
    "    if pts and isinstance(pts[0], (float, int)):\n",
    "        pts = list(zip(pts[::2], pts[1::2]))\n",
    "    \n",
    "    # Return the normalized list of (x, y) coordinate pairs.\n",
    "    return pts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each video exported from the CVAT annotation tool is organized into a structured folder that holds both the raw video data and its associated metadata. This structure typically includes:\n",
    "\n",
    "Raw Video Storage:\n",
    "The primary video file is saved in a dedicated folder, ensuring that the original footage is preserved intact.\n",
    "\n",
    "Metadata Files:\n",
    "Accompanying the raw video are metadata files (often in JSON format) that provide detailed information about the video, such as resolution, frame rate, and other relevant properties.\n",
    "\n",
    "Annotation Data:\n",
    "In addition to video metadata, the export includes detailed annotation files. These files contain information about label masks and polygon coordinates for each frame, which outline the annotated regions of interest within the video. This structured annotation data is essential for tasks like object detection and segmentation.\n",
    "\n",
    "This systematic folder organization makes it easy to access and process both the video content and its annotations, streamlining workflows for analysis and machine learning applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start processing of 52 videos\n",
      "Dataset include 3198 polygons.\n"
     ]
    }
   ],
   "source": [
    "# Initialize a list to hold rows extracted from annotations\n",
    "rows_to_append = []\n",
    "print(f\"Start processing of {df_filtere_videos.shape[0]} videos\")\n",
    "# Iterate over each row in the DataFrame containing filtered videos\n",
    "indexer = 0\n",
    "for index, video_df_row in df_filtere_videos.iterrows():\n",
    "    indexer = indexer +1\n",
    "    # Build the path to the 'data' folder within the current video's subfolder\n",
    "    data_folder_path = os.path.join(\n",
    "        CVAT_FOLDER_PATH, \n",
    "        video_df_row[\"video_subfolder_path\"], \n",
    "        'data'\n",
    "    )\n",
    "    \n",
    "    # Walk through the directory tree starting at data_folder_path.\n",
    "    # os.walk returns tuples of (current_path, directories, files)\n",
    "    folders_scan = [x for x in os.walk(data_folder_path)]\n",
    "    \n",
    "    # Retrieve the first subdirectory from the scan (assumes at least one exists)\n",
    "    video_folder = folders_scan[0][1][0]\n",
    "    \n",
    "    # Print the name of the video folder (for debugging or logging purposes)\n",
    "    # print(f' Video {video_df_row[\"video_id\"]} is processing')\n",
    "    \n",
    "    # Construct the full path to the video subfolder\n",
    "    path_video = os.path.join(\n",
    "        CVAT_FOLDER_PATH,\n",
    "        video_df_row[\"video_subfolder_path\"]\n",
    "    )\n",
    "    \n",
    "    # Open and load the annotations JSON file\n",
    "    with open(os.path.join(path_video, 'annotations.json')) as json_file:\n",
    "        json_anotation = json.load(json_file)\n",
    "    \n",
    "    # Open and load the task JSON file\n",
    "    with open(os.path.join(path_video, 'task.json')) as json_file:\n",
    "        task = json.load(json_file)\n",
    "\n",
    "    data = json_anotation[0]  # assuming you're working with the first element\n",
    "\n",
    "    # Case 1: Shapes are directly available\n",
    "    if 'shapes' in data and data['shapes']:\n",
    "        for shape in data['shapes']:\n",
    "            row = {\n",
    "                'polygon_id': id_generator(8),             # Generate a unique identifier for the shape\n",
    "                'video_id': video_df_row[\"video_id\"],        # Retrieve the video ID from the DataFrame row\n",
    "                'name_cvat': task[\"name\"],                   # Retrieve the task name from the task JSON\n",
    "                'type': shape[\"type\"],                       # The type of shape (e.g., polygon, rectangle)\n",
    "                'frame': int(shape[\"frame\"]),                # Convert the frame number to an integer\n",
    "                'polygon_label': shape.get(\"label\", \"\"),     # Use the shape's label if available\n",
    "                'points': parse_polygon_points(list(shape[\"points\"]))  # Parse the coordinate points\n",
    "            }\n",
    "            rows_to_append.append(row)\n",
    "\n",
    "    # Case 2: Shapes are nested inside tracks\n",
    "    elif 'tracks' in data and data['tracks']:\n",
    "        for track in data['tracks']:\n",
    "            # Use the track label if individual shapes do not have one\n",
    "            track_label = track.get(\"label\", \"\")\n",
    "            for shape in track.get(\"shapes\", []):\n",
    "                row = {\n",
    "                    'polygon_id': id_generator(8),\n",
    "                    'video_id': video_df_row[\"video_id\"],\n",
    "                    'name_cvat': task[\"name\"],\n",
    "                    'type': shape[\"type\"],\n",
    "                    'frame': int(shape[\"frame\"]),\n",
    "                    # Use the shape's label if present, otherwise use the track's label\n",
    "                    'polygon_label': shape.get(\"label\", track_label),\n",
    "                    'points': parse_polygon_points(list(shape[\"points\"]))\n",
    "                }\n",
    "                rows_to_append.append(row)\n",
    "\n",
    "df_polygons = pd.DataFrame(rows_to_append) \n",
    "print(f'Dataset include {df_polygons.shape[0]} polygons.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LP -> 17\n",
      "A -> 9\n",
      "P -> 26\n",
      "52\n"
     ]
    }
   ],
   "source": [
    "dffff = df_videos.loc[df_videos[\"video_id\"].isin(set(df_polygons[\"video_id\"]))]\n",
    "\n",
    "print(f'LP -> {dffff.loc[dffff[\"folder_class\"] == \"USG - Lung point\"].shape[0]}')\n",
    "print(f'A -> {dffff.loc[dffff[\"folder_class\"] == \"USG - Lung sliding absent (aj ine znaky - radiol. klin.)\"].shape[0]}')\n",
    "print(f'P -> {dffff.loc[dffff[\"folder_class\"] == \"USG - Lung sliding present (aj ine znaky - radiol. klin.)\"].shape[0]}')\n",
    "\n",
    "print(17 + 9 + 26)\n",
    "\n",
    "# dffff.loc[df_check[\"folder_class\"] == \"USG - Lung point\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polygon_id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>name_cvat</th>\n",
       "      <th>type</th>\n",
       "      <th>frame</th>\n",
       "      <th>polygon_label</th>\n",
       "      <th>points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DL4HRGVZ</td>\n",
       "      <td>PFFP3KRO</td>\n",
       "      <td>014 2021-10-18_125058_159.avi</td>\n",
       "      <td>polygon</td>\n",
       "      <td>0</td>\n",
       "      <td>lungslidingabsent</td>\n",
       "      <td>[(556.9000000000015, 200.3000000000011), (555....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P1HAR4EP</td>\n",
       "      <td>PFFP3KRO</td>\n",
       "      <td>014 2021-10-18_125058_159.avi</td>\n",
       "      <td>polygon</td>\n",
       "      <td>0</td>\n",
       "      <td>lungslidingabsent</td>\n",
       "      <td>[(359.705078125, 186.00537109375), (359.704868...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HNZ148Q1</td>\n",
       "      <td>PFFP3KRO</td>\n",
       "      <td>014 2021-10-18_125058_159.avi</td>\n",
       "      <td>polygon</td>\n",
       "      <td>10</td>\n",
       "      <td>lungslidingabsent</td>\n",
       "      <td>[(366.041015625, 185.21337890625), (366.040805...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L4NPYU7P</td>\n",
       "      <td>PFFP3KRO</td>\n",
       "      <td>014 2021-10-18_125058_159.avi</td>\n",
       "      <td>polygon</td>\n",
       "      <td>10</td>\n",
       "      <td>lungslidingabsent</td>\n",
       "      <td>[(556.9000000000015, 201.8000000000011), (555....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MKEDIUJ1</td>\n",
       "      <td>PFFP3KRO</td>\n",
       "      <td>014 2021-10-18_125058_159.avi</td>\n",
       "      <td>polygon</td>\n",
       "      <td>20</td>\n",
       "      <td>lungslidingabsent</td>\n",
       "      <td>[(556.1000000000004, 207.40000000000146), (555...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3193</th>\n",
       "      <td>FPN9AY85</td>\n",
       "      <td>T7EUVCFF</td>\n",
       "      <td>x220819--071841_20220819_MSK_0005s.AVI</td>\n",
       "      <td>polygon</td>\n",
       "      <td>260</td>\n",
       "      <td>lungslidingpresent</td>\n",
       "      <td>[(365.4625976562511, 203.77187500000036), (361...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3194</th>\n",
       "      <td>NOVTDJPC</td>\n",
       "      <td>T7EUVCFF</td>\n",
       "      <td>x220819--071841_20220819_MSK_0005s.AVI</td>\n",
       "      <td>polygon</td>\n",
       "      <td>270</td>\n",
       "      <td>lungslidingpresent</td>\n",
       "      <td>[(371.1701171875011, 203.13808593750036), (366...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3195</th>\n",
       "      <td>IH7B8HV8</td>\n",
       "      <td>T7EUVCFF</td>\n",
       "      <td>x220819--071841_20220819_MSK_0005s.AVI</td>\n",
       "      <td>polygon</td>\n",
       "      <td>280</td>\n",
       "      <td>lungslidingpresent</td>\n",
       "      <td>[(371.1701171875011, 202.50332031250036), (366...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>9JIMW44I</td>\n",
       "      <td>T7EUVCFF</td>\n",
       "      <td>x220819--071841_20220819_MSK_0005s.AVI</td>\n",
       "      <td>polygon</td>\n",
       "      <td>290</td>\n",
       "      <td>lungslidingpresent</td>\n",
       "      <td>[(371.1706054687511, 202.50332031250036), (366...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>4QK18MVC</td>\n",
       "      <td>T7EUVCFF</td>\n",
       "      <td>x220819--071841_20220819_MSK_0005s.AVI</td>\n",
       "      <td>polygon</td>\n",
       "      <td>299</td>\n",
       "      <td>lungslidingpresent</td>\n",
       "      <td>[(371.1706054687511, 202.50332031250036), (366...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3198 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     polygon_id  video_id                               name_cvat     type  \\\n",
       "0      DL4HRGVZ  PFFP3KRO           014 2021-10-18_125058_159.avi  polygon   \n",
       "1      P1HAR4EP  PFFP3KRO           014 2021-10-18_125058_159.avi  polygon   \n",
       "2      HNZ148Q1  PFFP3KRO           014 2021-10-18_125058_159.avi  polygon   \n",
       "3      L4NPYU7P  PFFP3KRO           014 2021-10-18_125058_159.avi  polygon   \n",
       "4      MKEDIUJ1  PFFP3KRO           014 2021-10-18_125058_159.avi  polygon   \n",
       "...         ...       ...                                     ...      ...   \n",
       "3193   FPN9AY85  T7EUVCFF  x220819--071841_20220819_MSK_0005s.AVI  polygon   \n",
       "3194   NOVTDJPC  T7EUVCFF  x220819--071841_20220819_MSK_0005s.AVI  polygon   \n",
       "3195   IH7B8HV8  T7EUVCFF  x220819--071841_20220819_MSK_0005s.AVI  polygon   \n",
       "3196   9JIMW44I  T7EUVCFF  x220819--071841_20220819_MSK_0005s.AVI  polygon   \n",
       "3197   4QK18MVC  T7EUVCFF  x220819--071841_20220819_MSK_0005s.AVI  polygon   \n",
       "\n",
       "      frame       polygon_label  \\\n",
       "0         0   lungslidingabsent   \n",
       "1         0   lungslidingabsent   \n",
       "2        10   lungslidingabsent   \n",
       "3        10   lungslidingabsent   \n",
       "4        20   lungslidingabsent   \n",
       "...     ...                 ...   \n",
       "3193    260  lungslidingpresent   \n",
       "3194    270  lungslidingpresent   \n",
       "3195    280  lungslidingpresent   \n",
       "3196    290  lungslidingpresent   \n",
       "3197    299  lungslidingpresent   \n",
       "\n",
       "                                                 points  \n",
       "0     [(556.9000000000015, 200.3000000000011), (555....  \n",
       "1     [(359.705078125, 186.00537109375), (359.704868...  \n",
       "2     [(366.041015625, 185.21337890625), (366.040805...  \n",
       "3     [(556.9000000000015, 201.8000000000011), (555....  \n",
       "4     [(556.1000000000004, 207.40000000000146), (555...  \n",
       "...                                                 ...  \n",
       "3193  [(365.4625976562511, 203.77187500000036), (361...  \n",
       "3194  [(371.1701171875011, 203.13808593750036), (366...  \n",
       "3195  [(371.1701171875011, 202.50332031250036), (366...  \n",
       "3196  [(371.1706054687511, 202.50332031250036), (366...  \n",
       "3197  [(371.1706054687511, 202.50332031250036), (366...  \n",
       "\n",
       "[3198 rows x 7 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_polygons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an instance ID for each polygon annotation.\n",
    "\n",
    "In a single frame, multiple polygons can be annotated, potentially with different labels. Additionally, it is possible\n",
    "to have multiple polygons of the same type within the same frame. In the original dataset, polygons corresponding to the\n",
    "same observed object across different frames do not share a common reference. Assigning a unique instance ID to each\n",
    "polygon is crucial for later interpolation operations, as it allows for linking and tracking the same object across frames.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from typing import List, Tuple, Union, Any\n",
    "\n",
    "def compute_polygon_centroid(poly: List[Tuple[Union[int, float], Union[int, float]]]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute the centroid of a polygon represented by a list of (x, y) tuples.\n",
    "    \n",
    "    The centroid is calculated as the arithmetic mean of the vertices.\n",
    "    \n",
    "    Parameters:\n",
    "        poly (List[Tuple[Union[int, float], Union[int, float]]]):\n",
    "            A list of (x, y) tuples representing the polygon's vertices.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: A numpy array containing the (x, y) coordinates of the centroid.\n",
    "    \"\"\"\n",
    "    # Convert the list of points into a numpy array for efficient computation.\n",
    "    pts = np.array(poly)\n",
    "    # Calculate the mean of x and y coordinates separately and return as a numpy array.\n",
    "    return np.array([pts[:, 0].mean(), pts[:, 1].mean()])\n",
    "\n",
    "\n",
    "def get_polygon_from_row(row: Any) -> List:\n",
    "    \"\"\"\n",
    "    Retrieve polygon data from a row of a DataFrame.\n",
    "    \n",
    "    This function checks for polygon data in two possible columns:\n",
    "      - 'interp_polygon': preferred if available.\n",
    "      - 'points': used if 'interp_polygon' is not available.\n",
    "    \n",
    "    Parameters:\n",
    "        row (Any): A dictionary-like object (e.g., a pandas Series) representing a row in the DataFrame.\n",
    "    \n",
    "    Returns:\n",
    "        List: A list representing the polygon points (assumed to be (x, y) tuples).\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: If neither 'interp_polygon' nor 'points' is found in the row.\n",
    "    \"\"\"\n",
    "    # Check for interpolated polygon data first.\n",
    "    poly = row.get('interp_polygon', None)\n",
    "    if poly is not None:\n",
    "        return poly\n",
    "    # Fallback to original points if interpolated data is not available.\n",
    "    poly = row.get('points', None)\n",
    "    if poly is not None:\n",
    "        return poly\n",
    "    # Raise an error if no polygon data is found.\n",
    "    raise ValueError(\"Row does not contain polygon data.\")\n",
    "\n",
    "\n",
    "def assign_tracks_poly(df_group: pd.DataFrame, max_distance: float = 50) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Assign consistent track IDs to polygon annotations across frames.\n",
    "    \n",
    "    For a given group (annotations from the same video and with the same polygon label),\n",
    "    this function assigns a unique \"polygon_track_id\" to each polygon such that the same\n",
    "    object is tracked across consecutive frames. This is achieved by comparing the centroids\n",
    "    of polygons between frames using the Hungarian algorithm to minimize the assignment cost.\n",
    "    \n",
    "    Parameters:\n",
    "        df_group (pd.DataFrame):\n",
    "            DataFrame containing polygon annotations for a single video and a specific polygon label.\n",
    "            Expected columns include \"frame\" and either \"interp_polygon\" or \"points\" for polygon data.\n",
    "        max_distance (float):\n",
    "            The maximum Euclidean distance allowed for linking two polygons across frames.\n",
    "            Polygons with a centroid distance exceeding this value are not considered the same object.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame:\n",
    "            A new DataFrame with an added \"polygon_track_id\" column that provides the track IDs.\n",
    "    \"\"\"\n",
    "    # Sort the group by frame to ensure temporal order.\n",
    "    df_group = df_group.sort_values(\"frame\").reset_index(drop=True)\n",
    "    \n",
    "    # Initialize the 'polygon_track_id' column with a default value of -1 (unassigned).\n",
    "    df_group[\"polygon_track_id\"] = -1\n",
    "    next_track_id = 0  # Counter for assigning new track IDs.\n",
    "\n",
    "    # List to store information about polygons from the previous frame.\n",
    "    # Each element is a dictionary with keys: \"track_id\" and \"centroid\".\n",
    "    prev_tracks = []\n",
    "\n",
    "    # Array to store the new track IDs corresponding to each row.\n",
    "    new_ids = np.empty(len(df_group), dtype=int)\n",
    "    \n",
    "    # Process the DataFrame frame by frame.\n",
    "    for frame, frame_df in df_group.groupby(\"frame\"):\n",
    "        # Get the indices of rows in the current frame.\n",
    "        idx = frame_df.index.tolist()\n",
    "        # List to store the computed centroids for polygons in the current frame.\n",
    "        centroids = []\n",
    "        for i in idx:\n",
    "            # Retrieve polygon data from the current row.\n",
    "            poly = get_polygon_from_row(df_group.loc[i])\n",
    "            # Compute the centroid for the polygon.\n",
    "            centroid = compute_polygon_centroid(poly)\n",
    "            centroids.append(centroid)\n",
    "        \n",
    "        # Initialize an array for storing track IDs for polygons in the current frame.\n",
    "        frame_ids = np.full(len(idx), -1, dtype=int)\n",
    "        \n",
    "        if not prev_tracks:\n",
    "            # For the first frame, assign a new track ID to every polygon.\n",
    "            for j in range(len(idx)):\n",
    "                frame_ids[j] = next_track_id\n",
    "                next_track_id += 1\n",
    "        else:\n",
    "            # Build a cost matrix where each entry is the Euclidean distance between\n",
    "            # a polygon in the previous frame and one in the current frame.\n",
    "            cost_matrix = np.zeros((len(prev_tracks), len(idx)))\n",
    "            for i, prev in enumerate(prev_tracks):\n",
    "                for j, current_centroid in enumerate(centroids):\n",
    "                    cost_matrix[i, j] = np.linalg.norm(prev[\"centroid\"] - current_centroid)\n",
    "            \n",
    "            # Use the Hungarian algorithm to determine the best assignment between previous and current polygons.\n",
    "            row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "            \n",
    "            # For each assignment, if the distance is within the allowed max_distance,\n",
    "            # assign the same track ID from the previous frame.\n",
    "            for r, c in zip(row_ind, col_ind):\n",
    "                if cost_matrix[r, c] <= max_distance:\n",
    "                    frame_ids[c] = prev_tracks[r][\"track_id\"]\n",
    "            \n",
    "            # For any polygon that did not receive a track ID, assign a new one.\n",
    "            for j in range(len(idx)):\n",
    "                if frame_ids[j] == -1:\n",
    "                    frame_ids[j] = next_track_id\n",
    "                    next_track_id += 1\n",
    "        \n",
    "        # Record the assigned track IDs for the current frame in the new_ids array.\n",
    "        for k, i in enumerate(idx):\n",
    "            new_ids[i] = frame_ids[k]\n",
    "        \n",
    "        # Update the prev_tracks list with polygons from the current frame for use in the next iteration.\n",
    "        prev_tracks = []\n",
    "        for j, i in enumerate(idx):\n",
    "            prev_tracks.append({\n",
    "                \"track_id\": frame_ids[j],\n",
    "                \"centroid\": centroids[j]\n",
    "            })\n",
    "    \n",
    "    # Assign the computed track IDs back to the DataFrame.\n",
    "    df_group[\"polygon_track_id\"] = new_ids\n",
    "    return df_group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Example Usage -----\n",
    "# Assume df_polygons_revision_9 is a DataFrame containing polygon annotations with the following columns:\n",
    "# \"video_id\", \"frame\", \"polygon_label\", and either \"points\" or \"interp_polygon\" for the polygon coordinates.\n",
    "\n",
    "# Group the DataFrame by 'video_id' and 'polygon_label', then apply the track assignment function to each group.\n",
    "df_polygons = (\n",
    "    df_polygons.groupby([\"video_id\", \"polygon_label\"], group_keys=False)\n",
    "             .apply(lambda g: assign_tracks_poly(g, max_distance=50))\n",
    "             .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# df_with_tracks now contains an additional column \"polygon_track_id\" that tracks polygon instances across frames.\n",
    "# df_polygons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polygons interpolation\n",
    "The program addresses a common challenge in video annotation: manually labeling every frame is extremely time-consuming. Typically, experts annotate only every 10th frame (or another interval), which means many intermediate frames lack direct annotations. To solve this, the program includes an interpolation module that calculates the polygon annotations for these in-between frames. By leveraging the annotations from the two nearest labeled frames, it estimates the positions and shapes of the polygons for all intervening frames, ensuring a complete and continuous labeling of the entire video sequence without requiring exhaustive manual work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def interpolate_points(polyA, polyB, t):\n",
    "    \"\"\"\n",
    "    Linearly interpolate between two polygons that each have the same number of vertices.\n",
    "    \n",
    "    Given two polygons, polyA and polyB, each represented as a list of (x, y) tuples, this function computes\n",
    "    an interpolated polygon by linearly blending each corresponding pair of vertices using the parameter t.\n",
    "    \n",
    "    The interpolation formula for each coordinate is:\n",
    "        interpolated_value = (1 - t) * value_A + t * value_B\n",
    "    where t is a fraction between 0 and 1:\n",
    "      - t = 0 yields polyA,\n",
    "      - t = 1 yields polyB,\n",
    "      - and values in between yield points along the straight line between the two vertices.\n",
    "    \n",
    "    Parameters:\n",
    "        polyA: list of (x, y) tuples representing the first polygon.\n",
    "        polyB: list of (x, y) tuples representing the second polygon.\n",
    "        t: float in [0, 1] representing the interpolation factor.\n",
    "    \n",
    "    Returns:\n",
    "        A list of (x, y) tuples representing the interpolated polygon.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    # Iterate over corresponding vertices of both polygons\n",
    "    for (xA, yA), (xB, yB) in zip(polyA, polyB):\n",
    "        # Compute the linear interpolation for x and y separately.\n",
    "        x = (1 - t) * xA + t * xB\n",
    "        y = (1 - t) * yA + t * yB\n",
    "        result.append((x, y))\n",
    "    return result\n",
    "\n",
    "def interpolate_polygon_track(df_track):\n",
    "    \"\"\"\n",
    "    Interpolate polygon annotations over a track across consecutive frames.\n",
    "    \n",
    "    For a single track—identified by a unique combination of video_id and polygon_id—this function:\n",
    "      - Sorts the annotations by frame.\n",
    "      - Creates a complete DataFrame that includes every frame from the minimum to the maximum annotated frame.\n",
    "      - For each consecutive pair of annotated frames, it linearly interpolates the polygon points for \n",
    "        the frames in between using linear interpolation.\n",
    "      - Copies constant identification columns (such as video_id, polygon_id, name_cvat, polygon_label, type)\n",
    "        from the original annotations to the interpolated frames.\n",
    "      \n",
    "    The polygon is assumed to be stored in the \"points\" column, and the resulting interpolated polygon\n",
    "    is stored in a new column \"interp_polygon\".\n",
    "    \n",
    "    Mathematical Details:\n",
    "      - For two annotated frames f_start and f_end with known polygons poly_start and poly_end, the gap is defined\n",
    "        as (f_end - f_start). For each intermediate frame at an offset 'offset' from f_start, the interpolation \n",
    "        factor t is calculated as t = offset / gap.\n",
    "      - The function then uses the interpolate_points function to calculate the polygon for that frame.\n",
    "    \n",
    "    Parameters:\n",
    "        df_track (pd.DataFrame): DataFrame for a single polygon track with annotations.\n",
    "        max_distance: (not used in this function, but kept for consistency with overall pipeline).\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with an \"interp_polygon\" column containing interpolated polygon points for\n",
    "                      every frame in the track.\n",
    "    \"\"\"\n",
    "    # Sort the track by frame to maintain temporal order.\n",
    "    df_track = df_track.sort_values(\"frame\").reset_index(drop=True)\n",
    "    \n",
    "    # Create a DataFrame with one row per frame between the minimum and maximum annotated frames.\n",
    "    min_frame = df_track[\"frame\"].min()\n",
    "    max_frame = df_track[\"frame\"].max()\n",
    "    all_frames = pd.DataFrame({\"frame\": range(min_frame, max_frame + 1)})\n",
    "    \n",
    "    # Merge to ensure that annotated frames retain their original data.\n",
    "    merged = pd.merge(all_frames, df_track, on=\"frame\", how=\"left\")\n",
    "    \n",
    "    # Initialize a column to store interpolated polygon data.\n",
    "    merged[\"interp_polygon\"] = None\n",
    "    \n",
    "    # Identify the indices of rows that already have polygon annotations (i.e., \"points\" are available).\n",
    "    annotated_idx = merged[~merged[\"points\"].isna()].index\n",
    "    \n",
    "    # Process each pair of consecutive annotated frames.\n",
    "    for start_i, end_i in zip(annotated_idx, annotated_idx[1:]):\n",
    "        # Retrieve the frame numbers for the start and end of the current segment.\n",
    "        f_start = merged.loc[start_i, \"frame\"]\n",
    "        f_end = merged.loc[end_i, \"frame\"]\n",
    "        \n",
    "        # Get the polygon points from the start and end frames.\n",
    "        poly_start = merged.loc[start_i, \"points\"]  # Expected to be a list of (x,y) tuples.\n",
    "        poly_end = merged.loc[end_i, \"points\"]\n",
    "        \n",
    "        # Calculate the number of frames between the two annotated frames.\n",
    "        gap = f_end - f_start\n",
    "        \n",
    "        # For each frame in the gap, compute the interpolation factor t and the corresponding polygon.\n",
    "        for offset in range(gap + 1):\n",
    "            # If gap is 0 (shouldn't happen, but for safety), t defaults to 0.\n",
    "            t = offset / float(gap) if gap else 0\n",
    "            # Compute the interpolated polygon using linear interpolation on each vertex.\n",
    "            poly_interp = interpolate_points(poly_start, poly_end, t)\n",
    "            # Store the interpolated polygon in the corresponding row.\n",
    "            merged.at[start_i + offset, \"interp_polygon\"] = poly_interp\n",
    "    \n",
    "    # For frames that were originally annotated, ensure that interp_polygon matches the original points.\n",
    "    merged.loc[annotated_idx, \"interp_polygon\"] = merged.loc[annotated_idx, \"points\"]\n",
    "    \n",
    "    # Propagate constant identification columns from the original annotations to every row.\n",
    "    for col in [\"video_id\", \"polygon_id\", \"name_cvat\", \"polygon_label\", \"type\"]:\n",
    "        if col in df_track.columns:\n",
    "            merged[col] = df_track[col].iloc[0]\n",
    "    \n",
    "    return merged\n",
    "\n",
    "def interpolate_all_polygons(df, num_points=None):\n",
    "    \"\"\"\n",
    "    Interpolate polygon annotations for all polygon tracks in a DataFrame.\n",
    "    \n",
    "    This function processes a DataFrame that contains polygon annotations with columns such as\n",
    "    video_id, polygon_id, frame, and points. It groups the DataFrame by video_id and polygon_track_id,\n",
    "    and then applies interpolation for each group. The result is a DataFrame that contains an interpolated\n",
    "    polygon (\"interp_polygon\") for every frame in the range of each polygon track.\n",
    "    \n",
    "    Note:\n",
    "      - It assumes that the polygon points in \"points\" have the same number of vertices across annotations.\n",
    "        If they do not, a resampling step might be necessary prior to interpolation.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame containing polygon annotations.\n",
    "        num_points (optional): Parameter reserved for potential resampling of polygon vertices (not used here).\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: A new DataFrame with interpolated polygon annotations for each frame.\n",
    "    \"\"\"\n",
    "    df_result = (\n",
    "        df.groupby([\"video_id\", \"type\", \"polygon_label\",\"polygon_track_id\"], group_keys=True)\n",
    "          .apply(interpolate_polygon_track)\n",
    "          .reset_index(drop=True)\n",
    "    )\n",
    "    return df_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polygons count before interpolation -> 25758\n",
      "Polygons count before interpolation -> 25758\n"
     ]
    }
   ],
   "source": [
    "print(f'Polygons count before interpolation -> {df_polygons.shape[0]}')\n",
    "df_polygons = interpolate_all_polygons(df_polygons)  # filter for a given video)\n",
    "print(f'Polygons count before interpolation -> {df_polygons.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame</th>\n",
       "      <th>polygon_id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>name_cvat</th>\n",
       "      <th>type</th>\n",
       "      <th>polygon_label</th>\n",
       "      <th>points</th>\n",
       "      <th>polygon_track_id</th>\n",
       "      <th>interp_polygon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6T8OQ8BX</td>\n",
       "      <td>0CJ4LA0L</td>\n",
       "      <td>x211119--131441_20211119_MSK_0004 LPB.AVI</td>\n",
       "      <td>polygon</td>\n",
       "      <td>lungslidingabsent</td>\n",
       "      <td>[(437.1181640625, 223.267578125), (437.1182141...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[(437.1181640625, 223.267578125), (437.1182141...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6T8OQ8BX</td>\n",
       "      <td>0CJ4LA0L</td>\n",
       "      <td>x211119--131441_20211119_MSK_0004 LPB.AVI</td>\n",
       "      <td>polygon</td>\n",
       "      <td>lungslidingabsent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(438.00634765625006, 223.43082031250015), (43...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6T8OQ8BX</td>\n",
       "      <td>0CJ4LA0L</td>\n",
       "      <td>x211119--131441_20211119_MSK_0004 LPB.AVI</td>\n",
       "      <td>polygon</td>\n",
       "      <td>lungslidingabsent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(438.89453125, 223.59406250000032), (439.3945...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6T8OQ8BX</td>\n",
       "      <td>0CJ4LA0L</td>\n",
       "      <td>x211119--131441_20211119_MSK_0004 LPB.AVI</td>\n",
       "      <td>polygon</td>\n",
       "      <td>lungslidingabsent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(439.78271484375, 223.75730468750044), (440.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6T8OQ8BX</td>\n",
       "      <td>0CJ4LA0L</td>\n",
       "      <td>x211119--131441_20211119_MSK_0004 LPB.AVI</td>\n",
       "      <td>polygon</td>\n",
       "      <td>lungslidingabsent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(440.6708984375, 223.92054687500058), (441.67...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25753</th>\n",
       "      <td>295</td>\n",
       "      <td>AZVODFRA</td>\n",
       "      <td>Z8CJVCN7</td>\n",
       "      <td>x220721--094147_20220721_MSK_0001 s.AVI</td>\n",
       "      <td>polygon</td>\n",
       "      <td>lungslidingpresent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(333.83740234375, 257.38916015625), (330.0324...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25754</th>\n",
       "      <td>296</td>\n",
       "      <td>AZVODFRA</td>\n",
       "      <td>Z8CJVCN7</td>\n",
       "      <td>x220721--094147_20220721_MSK_0001 s.AVI</td>\n",
       "      <td>polygon</td>\n",
       "      <td>lungslidingpresent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(333.83740234375, 257.38916015625), (330.0324...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25755</th>\n",
       "      <td>297</td>\n",
       "      <td>AZVODFRA</td>\n",
       "      <td>Z8CJVCN7</td>\n",
       "      <td>x220721--094147_20220721_MSK_0001 s.AVI</td>\n",
       "      <td>polygon</td>\n",
       "      <td>lungslidingpresent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(333.83740234375, 257.38916015625), (330.0324...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25756</th>\n",
       "      <td>298</td>\n",
       "      <td>AZVODFRA</td>\n",
       "      <td>Z8CJVCN7</td>\n",
       "      <td>x220721--094147_20220721_MSK_0001 s.AVI</td>\n",
       "      <td>polygon</td>\n",
       "      <td>lungslidingpresent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(333.83740234375, 257.38916015625), (330.0324...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25757</th>\n",
       "      <td>299</td>\n",
       "      <td>AZVODFRA</td>\n",
       "      <td>Z8CJVCN7</td>\n",
       "      <td>x220721--094147_20220721_MSK_0001 s.AVI</td>\n",
       "      <td>polygon</td>\n",
       "      <td>lungslidingpresent</td>\n",
       "      <td>[(333.83740234375, 257.38916015625), (330.0324...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[(333.83740234375, 257.38916015625), (330.0324...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25758 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       frame polygon_id  video_id                                  name_cvat  \\\n",
       "0          0   6T8OQ8BX  0CJ4LA0L  x211119--131441_20211119_MSK_0004 LPB.AVI   \n",
       "1          1   6T8OQ8BX  0CJ4LA0L  x211119--131441_20211119_MSK_0004 LPB.AVI   \n",
       "2          2   6T8OQ8BX  0CJ4LA0L  x211119--131441_20211119_MSK_0004 LPB.AVI   \n",
       "3          3   6T8OQ8BX  0CJ4LA0L  x211119--131441_20211119_MSK_0004 LPB.AVI   \n",
       "4          4   6T8OQ8BX  0CJ4LA0L  x211119--131441_20211119_MSK_0004 LPB.AVI   \n",
       "...      ...        ...       ...                                        ...   \n",
       "25753    295   AZVODFRA  Z8CJVCN7    x220721--094147_20220721_MSK_0001 s.AVI   \n",
       "25754    296   AZVODFRA  Z8CJVCN7    x220721--094147_20220721_MSK_0001 s.AVI   \n",
       "25755    297   AZVODFRA  Z8CJVCN7    x220721--094147_20220721_MSK_0001 s.AVI   \n",
       "25756    298   AZVODFRA  Z8CJVCN7    x220721--094147_20220721_MSK_0001 s.AVI   \n",
       "25757    299   AZVODFRA  Z8CJVCN7    x220721--094147_20220721_MSK_0001 s.AVI   \n",
       "\n",
       "          type       polygon_label  \\\n",
       "0      polygon   lungslidingabsent   \n",
       "1      polygon   lungslidingabsent   \n",
       "2      polygon   lungslidingabsent   \n",
       "3      polygon   lungslidingabsent   \n",
       "4      polygon   lungslidingabsent   \n",
       "...        ...                 ...   \n",
       "25753  polygon  lungslidingpresent   \n",
       "25754  polygon  lungslidingpresent   \n",
       "25755  polygon  lungslidingpresent   \n",
       "25756  polygon  lungslidingpresent   \n",
       "25757  polygon  lungslidingpresent   \n",
       "\n",
       "                                                  points  polygon_track_id  \\\n",
       "0      [(437.1181640625, 223.267578125), (437.1182141...               0.0   \n",
       "1                                                    NaN               NaN   \n",
       "2                                                    NaN               NaN   \n",
       "3                                                    NaN               NaN   \n",
       "4                                                    NaN               NaN   \n",
       "...                                                  ...               ...   \n",
       "25753                                                NaN               NaN   \n",
       "25754                                                NaN               NaN   \n",
       "25755                                                NaN               NaN   \n",
       "25756                                                NaN               NaN   \n",
       "25757  [(333.83740234375, 257.38916015625), (330.0324...               0.0   \n",
       "\n",
       "                                          interp_polygon  \n",
       "0      [(437.1181640625, 223.267578125), (437.1182141...  \n",
       "1      [(438.00634765625006, 223.43082031250015), (43...  \n",
       "2      [(438.89453125, 223.59406250000032), (439.3945...  \n",
       "3      [(439.78271484375, 223.75730468750044), (440.5...  \n",
       "4      [(440.6708984375, 223.92054687500058), (441.67...  \n",
       "...                                                  ...  \n",
       "25753  [(333.83740234375, 257.38916015625), (330.0324...  \n",
       "25754  [(333.83740234375, 257.38916015625), (330.0324...  \n",
       "25755  [(333.83740234375, 257.38916015625), (330.0324...  \n",
       "25756  [(333.83740234375, 257.38916015625), (330.0324...  \n",
       "25757  [(333.83740234375, 257.38916015625), (330.0324...  \n",
       "\n",
       "[25758 rows x 9 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_polygons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create merge of pleuras - presnet & absent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.ops import unary_union\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.ops import unary_union, nearest_points\n",
    "# The helper function 'row_to_poly' is assumed to convert a DataFrame row containing a list of (x,y) points\n",
    "# into a Shapely Polygon object. This is a crucial step because subsequent operations (union, intersection, distance)\n",
    "# require working with geometric objects.\n",
    "def row_to_poly(row):\n",
    "    \"\"\"\n",
    "    Retrieve polygon data from a row.\n",
    "    Prefer 'interp_polygon'; if not present, use 'points'.\n",
    "    Return a Shapely Polygon, or None if conversion fails.\n",
    "    \"\"\"\n",
    "    \n",
    "    poly_data = row.get(\"interp_polygon\")\n",
    "    if poly_data is None:\n",
    "        poly_data = row.get(\"interp_polygon\")\n",
    "    try:\n",
    "        return Polygon(poly_data)\n",
    "    except Exception as e:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_lung_sliding_polygons(df, merge_threshold=20):\n",
    "    \"\"\"\n",
    "    For each video and frame in the input DataFrame (which must include polygon data in either \n",
    "    \"interp_polygon\" or \"points\"), check if both 'lungslidingabsent' and 'lungslidingpresent' polygons exist.\n",
    "    \n",
    "    If the polygons intersect or if the minimum distance between them is less than merge_threshold,\n",
    "    two new rows are created:puted lungpoint (as a point geometry) labeled as \"lungsliding\".\n",
    "    \n",
    "    The lungpoint is determined as follows:\n",
    "      - If the polygons intersect, it is the centroid of their intersection.\n",
    "      - If they do not intersect\n",
    "      - One row with the merged polygon labeled as \"lungpointpleura\".\n",
    "      - Another row with the com, it is the midpoint between the nearest points on each polygon.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame containing the polygon annotations.\n",
    "        merge_threshold (float): Maximum distance between polygons for merging.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Original DataFrame with the new merged rows appended.\n",
    "    \"\"\"\n",
    "    new_rows = []      # Store new rows for the merged polygons and lungpoints.\n",
    "    video_ids_seen = set()  # Track processed video IDs.\n",
    "\n",
    "    # Group by video_id and frame to process each frame individually.\n",
    "    grouped = df.groupby([\"video_id\", \"frame\"])\n",
    "    for (video_id, frame), group in grouped:\n",
    "        video_ids_seen.add(video_id)\n",
    "        \n",
    "        # Filter the rows by the two specific polygon labels.\n",
    "        absent = group[group[\"polygon_label\"] == \"lungslidingabsent\"]\n",
    "        present = group[group[\"polygon_label\"] == \"lungslidingpresent\"]\n",
    "\n",
    "        # Process only if both annotations are present.\n",
    "        if absent.empty or present.empty:\n",
    "            continue\n",
    "\n",
    "        # Convert rows to Shapely Polygons for 'absent'.\n",
    "        polys_abs = []\n",
    "        for idx, row in absent.iterrows():\n",
    "            poly = row_to_poly(row)\n",
    "            if poly is not None:\n",
    "                if not poly.is_valid:\n",
    "                    poly = poly.buffer(0)\n",
    "                polys_abs.append(poly)\n",
    "        # Convert rows to Shapely Polygons for 'present'.\n",
    "        polys_pres = []\n",
    "        for idx, row in present.iterrows():\n",
    "            poly = row_to_poly(row)\n",
    "            if poly is not None:\n",
    "                if not poly.is_valid:\n",
    "                    poly = poly.buffer(0)\n",
    "                polys_pres.append(poly)\n",
    "\n",
    "        # Skip if polygon conversion failed.\n",
    "        if not polys_abs or not polys_pres:\n",
    "            continue\n",
    "\n",
    "        # Compute the union of polygons for each annotation type.\n",
    "        union_abs = unary_union(polys_abs)\n",
    "        union_pres = unary_union(polys_pres)\n",
    "\n",
    "        # Initialize lungpoint as None.\n",
    "        lungpoint = None\n",
    "        \n",
    "        # Check if the unions intersect or are close enough.\n",
    "        if union_abs.intersects(union_pres) or (union_abs.distance(union_pres) < merge_threshold):\n",
    "            # Merge the unions.\n",
    "            merged_poly = union_abs.union(union_pres)\n",
    "            if merged_poly.geom_type == \"MultiPolygon\":\n",
    "                merged_poly = merged_poly.convex_hull\n",
    "\n",
    "            # Determine the lungpoint location.\n",
    "            if union_abs.intersects(union_pres):\n",
    "                # Use the centroid of the intersection.\n",
    "                intersection = union_abs.intersection(union_pres)\n",
    "                lungpoint = intersection.centroid\n",
    "            else:\n",
    "                # Compute nearest points and then the midpoint.\n",
    "                p1, p2 = nearest_points(union_abs, union_pres)\n",
    "                lungpoint = type(p1)([ (p1.x + p2.x) / 2.0, (p1.y + p2.y) / 2.0 ])\n",
    "            \n",
    "            # Create a new row for the merged polygon with label \"lungpointpleura\".\n",
    "            merged_row = {\n",
    "                \"video_id\": video_id,\n",
    "                \"frame\": frame,\n",
    "                \"name_cvat\": group[\"name_cvat\"].iloc[0] if \"name_cvat\" in group.columns else None,\n",
    "                \"type\": group[\"type\"].iloc[0] if \"type\" in group.columns else None,\n",
    "                \"polygon_label\": \"lungpointpleura\",\n",
    "                \"interp_polygon\": list(merged_poly.exterior.coords),\n",
    "                \"points\": list(merged_poly.exterior.coords)\n",
    "            }\n",
    "            new_rows.append(merged_row)\n",
    "            \n",
    "            # Create a separate row for the lungpoint (as a point geometry) with label \"lungsliding\".\n",
    "            point_row = {\n",
    "                \"video_id\": video_id,\n",
    "                \"frame\": frame,\n",
    "                \"name_cvat\": group[\"name_cvat\"].iloc[0] if \"name_cvat\" in group.columns else None,\n",
    "                \"type\": group[\"type\"].iloc[0] if \"type\" in group.columns else None,\n",
    "                \"polygon_label\": \"lungpoint\",\n",
    "                # Represent the point geometry as a single coordinate in a list.\n",
    "                \"interp_polygon\": [(lungpoint.x, lungpoint.y)],\n",
    "                \"points\": [(lungpoint.x, lungpoint.y)]\n",
    "            }\n",
    "            new_rows.append(point_row)\n",
    "    \n",
    "    print(f\"Processed {len(video_ids_seen)} videos.\")\n",
    "    # Append the new rows to the original DataFrame if any were created.\n",
    "    if new_rows:\n",
    "        df_new = pd.DataFrame(new_rows)\n",
    "        df_out = pd.concat([df, df_new], ignore_index=True)\n",
    "        return df_out\n",
    "    else:\n",
    "        print(\"No merged polygons created.\")\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 52 videos.\n"
     ]
    }
   ],
   "source": [
    "# ----- Example Usage -----\n",
    "# Assume df_interpolated is your DataFrame after polygon interpolation.\n",
    "# It should include columns like: \"video_id_x\", \"frame\", \"name_cvat\", \"type\", \"polygon_label\",\n",
    "# and either \"interp_polygon\" or \"points\" (each as a list of (x,y) tuples).\n",
    "\n",
    "df_polygons = merge_lung_sliding_polygons(df_polygons, merge_threshold=60)\n",
    "# print(\"Merged rows with 'lungpointpleura':\")\n",
    "# print(df_merged[df_merged[\"polygon_label\"] == \"lungpointpleura\"].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame</th>\n",
       "      <th>polygon_id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>name_cvat</th>\n",
       "      <th>type</th>\n",
       "      <th>polygon_label</th>\n",
       "      <th>points</th>\n",
       "      <th>polygon_track_id</th>\n",
       "      <th>interp_polygon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6T8OQ8BX</td>\n",
       "      <td>0CJ4LA0L</td>\n",
       "      <td>x211119--131441_20211119_MSK_0004 LPB.AVI</td>\n",
       "      <td>polygon</td>\n",
       "      <td>lungslidingabsent</td>\n",
       "      <td>[(437.1181640625, 223.267578125), (437.1182141...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[(437.1181640625, 223.267578125), (437.1182141...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6T8OQ8BX</td>\n",
       "      <td>0CJ4LA0L</td>\n",
       "      <td>x211119--131441_20211119_MSK_0004 LPB.AVI</td>\n",
       "      <td>polygon</td>\n",
       "      <td>lungslidingabsent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(438.00634765625006, 223.43082031250015), (43...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6T8OQ8BX</td>\n",
       "      <td>0CJ4LA0L</td>\n",
       "      <td>x211119--131441_20211119_MSK_0004 LPB.AVI</td>\n",
       "      <td>polygon</td>\n",
       "      <td>lungslidingabsent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(438.89453125, 223.59406250000032), (439.3945...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6T8OQ8BX</td>\n",
       "      <td>0CJ4LA0L</td>\n",
       "      <td>x211119--131441_20211119_MSK_0004 LPB.AVI</td>\n",
       "      <td>polygon</td>\n",
       "      <td>lungslidingabsent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(439.78271484375, 223.75730468750044), (440.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6T8OQ8BX</td>\n",
       "      <td>0CJ4LA0L</td>\n",
       "      <td>x211119--131441_20211119_MSK_0004 LPB.AVI</td>\n",
       "      <td>polygon</td>\n",
       "      <td>lungslidingabsent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(440.6708984375, 223.92054687500058), (441.67...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46365</th>\n",
       "      <td>297</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YOBBHM8M</td>\n",
       "      <td>x220425--091211_20220425_MSK_0004lp.AVI</td>\n",
       "      <td>polygon</td>\n",
       "      <td>lungpoint</td>\n",
       "      <td>[(403.48615050862213, 255.95520820372263)]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(403.48615050862213, 255.95520820372263)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46366</th>\n",
       "      <td>298</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YOBBHM8M</td>\n",
       "      <td>x220425--091211_20220425_MSK_0004lp.AVI</td>\n",
       "      <td>polygon</td>\n",
       "      <td>lungpointpleura</td>\n",
       "      <td>[(424.5855183361883, 239.41720878850174), (399...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(424.5855183361883, 239.41720878850174), (399...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46367</th>\n",
       "      <td>298</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YOBBHM8M</td>\n",
       "      <td>x220425--091211_20220425_MSK_0004lp.AVI</td>\n",
       "      <td>polygon</td>\n",
       "      <td>lungpoint</td>\n",
       "      <td>[(403.5353102191025, 255.94643054296756)]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(403.5353102191025, 255.94643054296756)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46368</th>\n",
       "      <td>299</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YOBBHM8M</td>\n",
       "      <td>x220425--091211_20220425_MSK_0004lp.AVI</td>\n",
       "      <td>polygon</td>\n",
       "      <td>lungpointpleura</td>\n",
       "      <td>[(424.6869723292439, 239.41720878850174), (399...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(424.6869723292439, 239.41720878850174), (399...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46369</th>\n",
       "      <td>299</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YOBBHM8M</td>\n",
       "      <td>x220425--091211_20220425_MSK_0004lp.AVI</td>\n",
       "      <td>polygon</td>\n",
       "      <td>lungpoint</td>\n",
       "      <td>[(403.58446992958284, 255.9376528822125)]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(403.58446992958284, 255.9376528822125)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46370 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       frame polygon_id  video_id                                  name_cvat  \\\n",
       "0          0   6T8OQ8BX  0CJ4LA0L  x211119--131441_20211119_MSK_0004 LPB.AVI   \n",
       "1          1   6T8OQ8BX  0CJ4LA0L  x211119--131441_20211119_MSK_0004 LPB.AVI   \n",
       "2          2   6T8OQ8BX  0CJ4LA0L  x211119--131441_20211119_MSK_0004 LPB.AVI   \n",
       "3          3   6T8OQ8BX  0CJ4LA0L  x211119--131441_20211119_MSK_0004 LPB.AVI   \n",
       "4          4   6T8OQ8BX  0CJ4LA0L  x211119--131441_20211119_MSK_0004 LPB.AVI   \n",
       "...      ...        ...       ...                                        ...   \n",
       "46365    297        NaN  YOBBHM8M    x220425--091211_20220425_MSK_0004lp.AVI   \n",
       "46366    298        NaN  YOBBHM8M    x220425--091211_20220425_MSK_0004lp.AVI   \n",
       "46367    298        NaN  YOBBHM8M    x220425--091211_20220425_MSK_0004lp.AVI   \n",
       "46368    299        NaN  YOBBHM8M    x220425--091211_20220425_MSK_0004lp.AVI   \n",
       "46369    299        NaN  YOBBHM8M    x220425--091211_20220425_MSK_0004lp.AVI   \n",
       "\n",
       "          type      polygon_label  \\\n",
       "0      polygon  lungslidingabsent   \n",
       "1      polygon  lungslidingabsent   \n",
       "2      polygon  lungslidingabsent   \n",
       "3      polygon  lungslidingabsent   \n",
       "4      polygon  lungslidingabsent   \n",
       "...        ...                ...   \n",
       "46365  polygon          lungpoint   \n",
       "46366  polygon    lungpointpleura   \n",
       "46367  polygon          lungpoint   \n",
       "46368  polygon    lungpointpleura   \n",
       "46369  polygon          lungpoint   \n",
       "\n",
       "                                                  points  polygon_track_id  \\\n",
       "0      [(437.1181640625, 223.267578125), (437.1182141...               0.0   \n",
       "1                                                    NaN               NaN   \n",
       "2                                                    NaN               NaN   \n",
       "3                                                    NaN               NaN   \n",
       "4                                                    NaN               NaN   \n",
       "...                                                  ...               ...   \n",
       "46365         [(403.48615050862213, 255.95520820372263)]               NaN   \n",
       "46366  [(424.5855183361883, 239.41720878850174), (399...               NaN   \n",
       "46367          [(403.5353102191025, 255.94643054296756)]               NaN   \n",
       "46368  [(424.6869723292439, 239.41720878850174), (399...               NaN   \n",
       "46369          [(403.58446992958284, 255.9376528822125)]               NaN   \n",
       "\n",
       "                                          interp_polygon  \n",
       "0      [(437.1181640625, 223.267578125), (437.1182141...  \n",
       "1      [(438.00634765625006, 223.43082031250015), (43...  \n",
       "2      [(438.89453125, 223.59406250000032), (439.3945...  \n",
       "3      [(439.78271484375, 223.75730468750044), (440.5...  \n",
       "4      [(440.6708984375, 223.92054687500058), (441.67...  \n",
       "...                                                  ...  \n",
       "46365         [(403.48615050862213, 255.95520820372263)]  \n",
       "46366  [(424.5855183361883, 239.41720878850174), (399...  \n",
       "46367          [(403.5353102191025, 255.94643054296756)]  \n",
       "46368  [(424.6869723292439, 239.41720878850174), (399...  \n",
       "46369          [(403.58446992958284, 255.9376528822125)]  \n",
       "\n",
       "[46370 rows x 9 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_polygons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract boudingboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "def extract_bbox(row):\n",
    "    \"\"\"\n",
    "    Extracts the bounding box from a row containing polygon points.\n",
    "    \n",
    "    Expects row[\"interp_polygon\"] to be either:\n",
    "      - a list of (x, y) tuples, e.g.\n",
    "            [(437.1181640625, 223.267578125), (437.1182141045156, 241.65905631659007), ...]\n",
    "      - or a string representation of such a list.\n",
    "      \n",
    "    The bounding box is computed as:\n",
    "      - bb_min_x: minimum x-coordinate\n",
    "      - bb_max_x: maximum x-coordinate\n",
    "      - bb_min_y: minimum y-coordinate\n",
    "      - bb_max_y: maximum y-coordinate\n",
    "    \n",
    "    Parameters:\n",
    "        row : pd.Series\n",
    "            A row of a DataFrame containing the \"interp_polygon\" column.\n",
    "    \n",
    "    Returns:\n",
    "        row : pd.Series\n",
    "            The input row with added keys: \"bb_min_x\", \"bb_max_x\", \"bb_min_y\", \"bb_max_y\".\n",
    "    \"\"\"\n",
    "    points = row[\"interp_polygon\"]\n",
    "    # If points is a string, parse it into a list.\n",
    "    if isinstance(points, str):\n",
    "        points_list = np.array(ast.literal_eval(points))\n",
    "    else:\n",
    "        points_list = np.array(points)\n",
    "    \n",
    "    # points_list is expected to be of shape (n, 2), where n is the number of vertices.\n",
    "    row[\"bb_min_x\"] = points_list[:, 0].min()\n",
    "    row[\"bb_max_x\"] = points_list[:, 0].max()\n",
    "    row[\"bb_min_y\"] = points_list[:, 1].min()\n",
    "    row[\"bb_max_y\"] = points_list[:, 1].max()\n",
    "    return row\n",
    "\n",
    "# Example usage:\n",
    "df = df_polygons.copy()\n",
    "df_polygons = df.apply(extract_bbox, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polygons.to_json('/home/mh731nk/_data/experiments_tmp/data/revision_8/lp_polygons.json', orient='index', indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mh731nk_apvv-lung-eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
